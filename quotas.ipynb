{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f82eef",
   "metadata": {},
   "source": [
    "## Get subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e63c0b-dce5-4c8d-a27c-c7ab67739cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from azure.mgmt.subscription import SubscriptionClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "sub_client = SubscriptionClient(credential)\n",
    "subscription = next(sub_client.subscriptions.list(), None)\n",
    "if not subscription:\n",
    "    raise Exception(\"Authenticate using the az cli\")\n",
    "subscriptionId = subscription.subscription_id\n",
    "print(f\"Using subscription {subscriptionId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f06e6",
   "metadata": {},
   "source": [
    "## Getting regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = credential.get_token('https://management.azure.com/.default')\n",
    "headers = {'Authorization': 'Bearer ' + token.token}\n",
    "\n",
    "unique_region_names = set()\n",
    "\n",
    "locations_request = f\"https://management.azure.com/subscriptions/{subscriptionId}/locations?api-version=2021-04-01\"\n",
    "\n",
    "response = requests.get(locations_request, headers=headers)\n",
    "\n",
    "data = json.loads(response.text)\n",
    "\n",
    "for item in data[\"value\"]:\n",
    "    unique_region_names.add(item[\"name\"])\n",
    "\n",
    "regions_list = list(unique_region_names)\n",
    "\n",
    "print(regions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743342ec-c845-4c1f-8d69-c91cbf01b258",
   "metadata": {},
   "source": [
    "## Find regions where Azure AI is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad818e-8657-4077-b4fa-01bfe4854845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "regions_successful = []\n",
    "regions_failed = []\n",
    "\n",
    "def get_models(region):\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/models?api-version=2023-05-01\"\n",
    "    return (region, requests.get(url, headers=headers))\n",
    "\n",
    "with tqdm(total=len(regions_list)) as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=len(regions_list)) as ex:\n",
    "        futures = [ex.submit(get_models, region) for region in regions_list]\n",
    "        for future in as_completed(futures):\n",
    "            (region, result) = future.result()\n",
    "            if result.status_code == 200:\n",
    "                regions_successful.append(region)\n",
    "            else:\n",
    "                regions_failed.append(region)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "print(\"Potential Azure OpenAI regions based on control plane response:\")\n",
    "print(regions_successful)\n",
    "\n",
    "print(\"Azure OpenAI Not Supported:\")\n",
    "print(regions_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea60ee9-fb84-49db-b432-a8d38aafe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_model_data = {}  \n",
    "\n",
    "excluded_models =  ['text-similarity-ada-001', 'text-babbage-001', 'text-curie-001', 'text-similarity-curie-001', 'text-davinci-002','text-davinci-003', 'text-davinci-fine-tune-002', 'code-davinci-002', 'code-davinci-fine-tune-002','text-ada-001', 'text-search-ada-doc-001', 'text-search-ada-query-001', 'code-search-ada-code-001','code-search-ada-text-001', 'text-similarity-babbage-001', 'text-search-babbage-doc-001','text-search-babbage-query-001', 'code-search-babbage-code-001', 'code-search-babbage-text-001', 'text-search-curie-doc-001', 'text-search-curie-query-001', 'text-davinci-001','text-similarity-davinci-001', 'text-search-davinci-doc-001', 'text-search-davinci-query-001','code-cushman-001']\n",
    "\n",
    "for region in regions_successful:\n",
    "    model_request_url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/models?api-version=2023-05-01\"\n",
    "    model_response = requests.get(model_request_url, headers=headers)\n",
    "\n",
    "    response_dict = json.loads(model_response.text)\n",
    "    #print(response_dict)\n",
    "    data_test = []\n",
    "\n",
    "    for item in response_dict[\"value\"]:\n",
    "        model_name = None\n",
    "        version = None\n",
    "        sku_name = None\n",
    "        if item[\"model\"][\"capabilities\"].get(\"scaleType\") == \"Manual\": #skip legacy models\n",
    "            continue\n",
    "        model_name = item[\"model\"][\"name\"]\n",
    "        if model_name in excluded_models: # if in list skip\n",
    "            continue\n",
    "        version = item[\"model\"][\"version\"]\n",
    "        rdate = item[\"model\"][\"deprecation\"]\n",
    "        for sku in item[\"model\"][\"skus\"]:\n",
    "            sku_name = sku[\"name\"]\n",
    "        if sku_name == \"Standard\": # This example is only targeting Standard Model deployments SKUI\n",
    "            data_test.append({\"Model Name\": model_name, \"Version\": version, \"SKU Name\": sku_name})\n",
    "                #print(data_test)\n",
    "\n",
    "    region_model_data[region] = data_test  # store the model data under corresponding region name\n",
    "\n",
    "# Print result\n",
    "for region, model_data in region_model_data.items():\n",
    "    print(f'{region}: {model_data}')\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792227a-a3a2-4310-8d7f-f927e3439f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for region, models in region_model_data.items():\n",
    "    for model in models:\n",
    "        row = model.copy()  \n",
    "        row['Region'] = region  \n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df[['Region', 'Model Name', 'Version', 'SKU Name']]\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df['Exist'] = True \n",
    "pivot_df = df.pivot_table(index='Region', columns=['Model Name', 'Version'], values='Exist', fill_value=False, aggfunc='any')\n",
    "pivot_df.reset_index(inplace = True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85086c3e-f327-4ef3-9b8a-c760cf27f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_model_quota_data = {}\n",
    "\n",
    "# List of models to exclude\n",
    "exclude_models = [\"Code-Cushman-001\", \"code-cushman-fine-tune-002\", \"Code-Search-Ada-Code-001\", \"Code-Search-Ada-Text-001\", \"Text-Ada-001\", \"Text-Search-Ada-Doc-001\", \"Text-Search-Ada-Query-001\", \"Text-Similarity-Ada-001\", \"Babbage\", \"Code-Search-Babbage-Code-001\", \"Code-Search-Babbage-Text-001\", \"Text-Babbage-001\", \"Text-Search-Babbage-Doc-001\", \"Text-Search-Babbage-Query-001\", \"Text-Similarity-Babbage-001\", \"Curie\", \"Text-Curie-001\", \"Text-Search-Curie-Doc-001\", \"Text-Search-Curie-Query-001\", \"Text-Similarity-Curie-001\", \"Code-Davinci-002\", \"Code-Davinci-Fine-Tune-002\", \"Davinci\", \"Text-Davinci-001\", \"Text-Davinci-002\", \"Text-Davinci-003\", \"Text-Davinci-Fine-Tune-002\", \"Text-Search-Davinci-Doc-001\", \"Text-Search-Davinci-Query-001\", \"Text-Similarity-Davinci-001\", \"Code-Cushman-001\", \"code-cushman-fine-tune-002\",  \"Ada\", \"Code-Search-Ada-Code-001\", \"Code-Search-Ada-Text-001\", \"Text-Ada-001\", \"Text-Search-Ada-Doc-001\", \"Text-Search-Ada-Query-001\", \"Text-Similarity-Ada-001\", \"Babbage\", \"Code-Search-Babbage-Code-001\", \"Code-Search-Babbage-Text-001\", \"Text-Babbage-001\", \"Text-Search-Babbage-Doc-001\", \"Text-Search-Babbage-Query-001\", \"Text-Similarity-Babbage-001\", \"Curie\", \"Text-Curie-001\", \"Text-Search-Curie-Doc-001\", \"Text-Search-Curie-Query-001\", \"Text-Similarity-Curie-001\", \"Code-Davinci-Fine-Tune-002\", \"Davinci\", \"Text-Davinci-001\", \"Text-Davinci-002\", \"Text-Davinci-003\", \"Text-Davinci-Fine-Tune-002\", \"Text-Search-Davinci-Doc-001\", \"Text-Search-Davinci-Query-001\", \"Text-Similarity-Davinci-001\"]\n",
    "\n",
    "for region in regions_successful:\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/usages?api-version=2023-05-01\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_dict = json.loads(response.text)\n",
    "\n",
    "    token_limit_details = []\n",
    "\n",
    "    \n",
    "    for item in response_dict['value']:\n",
    "        # Ignoring 'OpenAI.LowPriority.gpt-4' value\n",
    "        if item['name']['value'] == 'OpenAI.LowPriority.gpt-4':\n",
    "            continue\n",
    "\n",
    "        # Check if 'Tokens Per Minute' is in the localized value\n",
    "        if 'Tokens Per Minute' in item['name']['localizedValue']:\n",
    "        # Extract the localized value & limit.\n",
    "            localized_value = item['name']['localizedValue']\n",
    "            localized_value = localized_value.replace(\"Tokens Per Minute (thousands) - \", \"\")\n",
    "            limit = item['limit']\n",
    "            #print(localized_value)\n",
    "            #print(limit)\n",
    "\n",
    "            # If the model is not in the exclude list, add it to the token_limit_details\n",
    "            if localized_value not in exclude_models:\n",
    "                token_limit_details.append((localized_value, limit))\n",
    "            \n",
    "        elif 'Enqueued tokens' in item['name']['localizedValue']:\n",
    "        # Extract the localized value & limit.\n",
    "            localized_value = item['name']['localizedValue']\n",
    "            #print(localized_value)\n",
    "            localized_value = localized_value.replace(\"Enqueued tokens (thousands) - \", \"\")\n",
    "            localized_value = localized_value + \" - Global-Batch\"\n",
    "            #print(localized_value)\n",
    "            limit = item['limit']\n",
    "            #print(limit)\n",
    "        \n",
    "        # If the model is not in the exclude list, add it to the token_limit_details\n",
    "            if localized_value not in exclude_models:\n",
    "                token_limit_details.append((localized_value, limit))\n",
    "            \n",
    "    region_model_quota_data[region] = token_limit_details\n",
    "\n",
    "print(region_model_quota_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77721b-0ea3-46c2-8c0a-43f07796cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = [(region, lv, limit) for region in region_model_quota_data for lv, limit in region_model_quota_data[region]]\n",
    "\n",
    "    ## Convert the list to a DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=['Region', 'LocalizedValue', 'Limit'])\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    " \n",
    "    #print(df) \n",
    "pivot_df = df.pivot(index='Region', columns='LocalizedValue', values='Limit')\n",
    "pivot_df.reset_index(level=0, inplace=True)\n",
    "\n",
    "\n",
    "    # Specify the base column ordering you want\n",
    "column_order = [\"Region\", \"o1-mini\", \"o1\", \"gpt-4o\", \"gpt-4o-mini\", \"GPT-4\", \"GPT-4-32K\", \"GPT-4-Turbo\", \"GPT-4-Turbo-V\", \"GPT-35-Turbo\", \"GPT-35-Turbo-Instruct\", \"o1-mini - GlobalStandard\",  \"o1 - GlobalStandard\", \"gpt-4o - GlobalStandard\", \"gpt-4o-mini - GlobalStandard\", \"GPT-4-Turbo - GlobalStandard\", \"GPT-4o - Global-Batch\", \"GPT-4o-mini - Global-Batch\", \"GPT-4 - Global-Batch\", \"GPT-4-Turbo - Global-Batch\", \"gpt-35-turbo - Global-Batch\", \"Text-Embedding-Ada-002\", \"text-embedding-3-small\", \"text-embedding-3-large\", \"GPT-4o - finetune\", \"GPT-4o-mini - finetune\", \"GPT-4 - finetune\",  \"Babbage-002\", \"Babbage-002 - finetune\",\"Davinci-002\", \"Davinci-002 - finetune\",\"GPT-35-Turbo - finetune\", \"GPT-35-Turbo-1106 - finetune\"]\n",
    "\n",
    "# Create a set of column names from column_order and the current DataFrame\n",
    "set_column_order = set(column_order)\n",
    "set_existing_columns = set(pivot_df.columns)\n",
    "\n",
    "# New columns which are not in the column_order list\n",
    "new_columns = list(set_existing_columns - set_column_order)\n",
    "\n",
    "# Add the new columns to the end of the column_order list\n",
    "column_order = column_order + new_columns\n",
    "\n",
    "# Reorder the dataframe\n",
    "pivot_df = pivot_df[column_order]\n",
    "\n",
    "pivot_df.columns.name = None\n",
    "pivot_df.fillna(-1, inplace=True)\n",
    "numeric_columns = pivot_df.columns.drop('Region') #Get all numeric columns\n",
    "\n",
    "pivot_df[numeric_columns] = pivot_df[numeric_columns].astype(int)\n",
    "pivot_df[numeric_columns] = pivot_df[numeric_columns].applymap(lambda x: str(x) if x != -1 else '-')\n",
    "\n",
    "\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf62e6-a8e3-40d8-ae9b-d378b3b867a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
