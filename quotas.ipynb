{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f82eef",
   "metadata": {},
   "source": [
    "## Get subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e63c0b-dce5-4c8d-a27c-c7ab67739cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from azure.mgmt.subscription import SubscriptionClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "sub_client = SubscriptionClient(credential)\n",
    "subscription = next(sub_client.subscriptions.list(), None)\n",
    "if not subscription:\n",
    "    raise Exception(\"Authenticate using the az cli\")\n",
    "subscriptionId = subscription.subscription_id\n",
    "print(f\"Using subscription {subscriptionId}\")\n",
    "\n",
    "token = credential.get_token('https://management.azure.com/.default')\n",
    "headers = {'Authorization': 'Bearer ' + token.token}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f06e6",
   "metadata": {},
   "source": [
    "## Discover regions and geography groups using the Locations API\n",
    "\n",
    "### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions():\n",
    "    locations_request = f\"https://management.azure.com/subscriptions/{subscriptionId}/locations?api-version=2021-04-01\"\n",
    "    response = requests.get(locations_request, headers=headers)\n",
    "    data = json.loads(response.text)\n",
    "    return data[\"value\"]\n",
    "\n",
    "regions = get_regions()\n",
    "\n",
    "def get_region_names(regions):\n",
    "    return set([r['name'] for r in regions])\n",
    "\n",
    "regions_list = get_region_names(regions)\n",
    "print(f\"{len(regions_list)} regions:\")\n",
    "print(\", \".join(regions_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd349a-e719-4412-91a3-f5011a0cff1f",
   "metadata": {},
   "source": [
    "### Geography groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814dc95-97a4-4324-acbb-48107767489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geography_groups(regions):\n",
    "    return set([region['metadata']['geographyGroup'] for region in regions if 'geographyGroup' in region['metadata']])\n",
    "\n",
    "geography_groups = get_geography_groups(regions)\n",
    "print(\", \".join(geography_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7d142-7377-45c1-a4a8-fdc7abb13333",
   "metadata": {},
   "source": [
    "## Let's focus on US regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a21f27-0f53-4f41-ae04-0b80813abeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_geography_group(regions, *args):\n",
    "    return filter(lambda r: r['metadata']['geographyGroup'] in args, [r for r in regions if 'geographyGroup' in r['metadata']])\n",
    "regions_list = get_region_names(filter_by_geography_group(regions, 'US'))\n",
    "print(\", \".join(regions_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3167d-58a0-4d20-92a2-fb2ad88e8694",
   "metadata": {},
   "source": [
    "## Helper to parallelize calls per region\n",
    "\n",
    "Most of the API calls we'll need to make going forward are per region and we want to aggregate results across regions and depending on how many regions you are considering, you can find yourself querying up to 90 regions. The following helper will allow us to run queries in parallel for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942e184-d2b2-4a8a-9794-ba080d9acf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(fn, *iterables, executor=None, **kwargs):\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    \"\"\"\n",
    "    Equivalent to executor.map(fn, *iterables),\n",
    "    but displays a tqdm-based progress bar.\n",
    "    \n",
    "    Does not support timeout or chunksize as executor.submit is used internally\n",
    "    \n",
    "    **kwargs is passed to tqdm.\n",
    "    \"\"\"\n",
    "    with executor if executor else ThreadPoolExecutor(max_workers=len(regions_list)) as ex:\n",
    "        futures = []\n",
    "        for iterable in iterables:\n",
    "            futures += [ex.submit(fn, i) for i in iterable]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), **kwargs):\n",
    "            yield f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743342ec-c845-4c1f-8d69-c91cbf01b258",
   "metadata": {},
   "source": [
    "## Discover regions where Azure AI is supported using the Models API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad818e-8657-4077-b4fa-01bfe4854845",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_successful = []\n",
    "regions_failed = []\n",
    "\n",
    "def get_models_response(region):\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/models?api-version=2023-05-01\"\n",
    "    return (region, requests.get(url, headers=headers))\n",
    "\n",
    "for (region, result) in parallel_map(get_models_response, regions_list):\n",
    "    if result.status_code == 200:\n",
    "        regions_successful.append(region)\n",
    "    else:\n",
    "        regions_failed.append(region)\n",
    "\n",
    "print(\"Potential Azure OpenAI regions based on control plane response:\")\n",
    "print(\", \".join(regions_successful))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8032e-af68-4ff5-9629-18d1046e7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Azure OpenAI Not Supported:\")\n",
    "print(\", \".join(regions_failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564bf09-a83e-463e-a45c-e70480261ee3",
   "metadata": {},
   "source": [
    "## Discover models and SKUs using the Models API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4e937-6d43-402f-b7de-34db8bdf4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(region):\n",
    "    (_, response) = get_models_response(region)\n",
    "    parsed = json.loads(response.text)\n",
    "    return parsed['value']\n",
    "\n",
    "def get_models_regions(regions):\n",
    "    def get_models_region(region):\n",
    "        return [{\n",
    "            \"model\": model,\n",
    "            \"region\": region\n",
    "        } for model in get_models(region)]\n",
    "\n",
    "    import itertools\n",
    "    return itertools.chain.from_iterable(parallel_map(get_models_region, regions))\n",
    "\n",
    "models_regions = list(get_models_regions(regions_successful))\n",
    "models_regions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea60ee9-fb84-49db-b432-a8d38aafe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_model_data = {}  \n",
    "\n",
    "excluded_models =  ['text-similarity-ada-001', 'text-babbage-001', 'text-curie-001', 'text-similarity-curie-001', 'text-davinci-002','text-davinci-003', 'text-davinci-fine-tune-002', 'code-davinci-002', 'code-davinci-fine-tune-002','text-ada-001', 'text-search-ada-doc-001', 'text-search-ada-query-001', 'code-search-ada-code-001','code-search-ada-text-001', 'text-similarity-babbage-001', 'text-search-babbage-doc-001','text-search-babbage-query-001', 'code-search-babbage-code-001', 'code-search-babbage-text-001', 'text-search-curie-doc-001', 'text-search-curie-query-001', 'text-davinci-001','text-similarity-davinci-001', 'text-search-davinci-doc-001', 'text-search-davinci-query-001','code-cushman-001']\n",
    "\n",
    "for region in regions_successful:\n",
    "    data_test = []\n",
    "\n",
    "    for item in get_models(region):\n",
    "        model_name = None\n",
    "        version = None\n",
    "        sku_name = None\n",
    "        if item[\"model\"][\"capabilities\"].get(\"scaleType\") == \"Manual\": #skip legacy models\n",
    "            continue\n",
    "        model_name = item[\"model\"][\"name\"]\n",
    "        if model_name in excluded_models: # if in list skip\n",
    "            continue\n",
    "        version = item[\"model\"][\"version\"]\n",
    "        rdate = item[\"model\"][\"deprecation\"]\n",
    "        for sku in item[\"model\"][\"skus\"]:\n",
    "            sku_name = sku[\"name\"]\n",
    "        if sku_name == \"Standard\": # This example is only targeting Standard Model deployments SKUI\n",
    "            data_test.append({\"Model Name\": model_name, \"Version\": version, \"SKU Name\": sku_name})\n",
    "                #print(data_test)\n",
    "\n",
    "    region_model_data[region] = data_test  # store the model data under corresponding region name\n",
    "\n",
    "# Print result\n",
    "#for region, model_data in region_model_data.items():\n",
    "#    print(f'{region}: {model_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792227a-a3a2-4310-8d7f-f927e3439f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for region, models in region_model_data.items():\n",
    "    for model in models:\n",
    "        row = model.copy()  \n",
    "        row['Region'] = region  \n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df[['Region', 'Model Name', 'Version', 'SKU Name']]\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df['Exist'] = True \n",
    "pivot_df = df.pivot_table(index='Region', columns=['Model Name', 'Version'], values='Exist', fill_value=False, aggfunc='any')\n",
    "pivot_df.reset_index(inplace = True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc05d8d-9792-4fc1-ad6a-ac0d4340b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_type(usage_name_localized_value):\n",
    "    if 'Tokens Per Minute' in usage_name_localized_value:\n",
    "        return 'tokens-per-minute'\n",
    "    elif 'Requests Per Minute' in usage_name_localized_value:\n",
    "        return 'requests-per-minute'\n",
    "    elif 'Enqueued tokens' in usage_name_localized_value:\n",
    "        return 'enqueued-tokens'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_model_info(usage):\n",
    "    '''Extracts model vendor, SKU and name from the value using regular expressions.\n",
    "    Value example: OpenAI.Standard.gpt-35-turbo or OpenAI.Standard.gpt-35-turbo-finetune'''\n",
    "    localized = usage['name']['localizedValue'].lower()\n",
    "    if not 'tokens' in localized and not 'requests' in localized: # Skip if not a token usage\n",
    "        return\n",
    "    # Updated pattern to match finetune suffix and classify work type\n",
    "    pattern = r'(?P<vendor>\\w+)\\.(?P<SKU>\\w+)\\.(?P<name>[\\w-]+?)(?:-finetune)?$'\n",
    "    match = re.match(pattern, usage['name']['value'])\n",
    "    if match:\n",
    "        result = match.groupdict()\n",
    "        # Determine work type based on the presence of the 'finetune' suffix\n",
    "        result['workload'] = 'finetune' if usage['name']['value'].endswith('-finetune') else 'inference'\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "def extract_usage_details(region, usage):\n",
    "    '''Extracts region, name, localizedValue, type, currentValue, limit, unit from the item'''\n",
    "    model_info = extract_model_info(usage)\n",
    "    currentValue = usage['currentValue']\n",
    "    limit = usage['limit']\n",
    "    if 'thousands' in usage['name']['localizedValue']:\n",
    "        currentValue *= 1000\n",
    "        limit *= 1000\n",
    "    remaining = limit - currentValue\n",
    "    return {\n",
    "        'region': region,\n",
    "        'value': usage['name']['value'],\n",
    "        'localizedValue': usage['name']['localizedValue'],\n",
    "        'type': infer_type(usage['name']['localizedValue']),\n",
    "        'modelName': model_info['name'] if model_info else None,\n",
    "        'vendor': model_info['vendor'] if model_info else None,\n",
    "        'SKU': model_info['SKU'] if model_info else None,\n",
    "        'workload': model_info['workload'] if model_info else None,\n",
    "        'current': currentValue,\n",
    "        'remaining': remaining,\n",
    "        'limit': limit,\n",
    "        'unit': usage['unit']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c647e2-130e-463a-bd71-9225ce8ae6d7",
   "metadata": {},
   "source": [
    "## Discover quotas using the Usages API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85086c3e-f327-4ef3-9b8a-c760cf27f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usages(region):\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/usages?api-version=2023-05-01\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return json.loads(response.text)['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb836b14-9e37-4ae0-8d4e-cad9682643f4",
   "metadata": {},
   "source": [
    "### Example for eastus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a79ae-9097-439c-9904-2151e188e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usages = get_usages('eastus2')\n",
    "usages[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab765dd-d980-43b1-a519-0ff79eda443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regions_usages(regions):\n",
    "    import itertools\n",
    "    def get_region_usages(region):\n",
    "        return (region, get_usages(region))\n",
    "    return dict(parallel_map(get_region_usages, regions))\n",
    "\n",
    "regional_usages = get_regions_usages(regions_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4000e-da5f-4936-ae64-6ba19ea73cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_limit_details = [extract_usage_details(region, usage) for (region, usages) in list(regional_usages.items()) for usage in usages]\n",
    "token_limit_details\n",
    "\n",
    "## Convert the list to a DataFrame\n",
    "df = pd.DataFrame(token_limit_details)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df[df['modelName'].notnull()].head()\n",
    "#df[df['modelName'] == 'gpt-4o']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c86b67-b89c-45a0-bf52-d999f2b48a10",
   "metadata": {},
   "source": [
    "### Index usages by name and region\n",
    "\n",
    "We will use this index to join usages with the models on the usage name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739867c-19fe-4e9f-a4ea-aa626712c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_usages_by_name(usages):\n",
    "    from functools import reduce\n",
    "    def usage_name_reducer(j, u):\n",
    "        j[u['name']['value']] = u\n",
    "        return j\n",
    "    return reduce(usage_name_reducer, usages, {})\n",
    "\n",
    "regional_usages_by_name = dict([(region, index_usages_by_name(usages)) for (region, usages) in regional_usages.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4df935-de4f-4d8e-a59c-f79bfb022e01",
   "metadata": {},
   "source": [
    "## Join models with SKUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9c964-b9ee-439b-a3f5-9537611fb432",
   "metadata": {},
   "source": [
    "SKUs are listed as an array under each model. We want one SKU per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88626eda-64b3-46ff-a027-03782fd95a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_models_sku(models_region):\n",
    "    for model_join in models_region:\n",
    "        model = model_join['model']\n",
    "        skus = model['model']['skus'] or [None]\n",
    "        for sku in skus:\n",
    "            yield model_join | {\n",
    "                \"sku\": sku\n",
    "            }\n",
    "models_flattened = list(flatten_models_sku(models_regions))\n",
    "models_flattened[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec0454-41ac-48df-8392-16011beb64de",
   "metadata": {},
   "source": [
    "## Join models with usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b55e75-edf5-475b-8242-b04db95c18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_models_usages(models_flattened, regional_usages_by_name):\n",
    "    for model_join in models_flattened:\n",
    "        model = model_join['model']\n",
    "        sku = model_join['sku']\n",
    "        region = model_join['region']\n",
    "        usage = None\n",
    "        if sku:\n",
    "            usageName = sku['usageName']\n",
    "            usages_by_name = regional_usages_by_name[region]\n",
    "            usage = usages_by_name[usageName]\n",
    "        yield model_join | {\n",
    "            \"usage\": usage\n",
    "        }\n",
    "\n",
    "joined_model_sku_usages = list(join_models_usages(models_flattened, regional_usages_by_name))\n",
    "joined_model_sku_usages[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c8925-a154-4ba3-8acf-a436972f2583",
   "metadata": {},
   "source": [
    "## Find models matching name, TPM and SKU requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060ccd6-6f8a-480d-b034-26d81a313b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_matches(model_names, tpm, sku_names):\n",
    "    def criteria(model, sku, usage, **kwargs):\n",
    "        if not usage:\n",
    "            return False\n",
    "        limit = usage['limit']\n",
    "        current = usage['currentValue']\n",
    "        remaining = limit - current\n",
    "        model_name = model['model']['name']\n",
    "        sku_name = sku['name']\n",
    "        matches = True\n",
    "        if model_names:\n",
    "            matches = matches and model_name in model_names\n",
    "        if sku_names:\n",
    "            matches = matches and sku_name in sku_names\n",
    "        if tpm:\n",
    "            matches = matches and remaining >= tpm\n",
    "        return matches\n",
    "    return criteria\n",
    "\n",
    "def __or__(p1, p2):\n",
    "    def pred(*args, **kwargs):\n",
    "        return p1(*args, **kwargs) or p2(*args, **kwargs)\n",
    "    return pred\n",
    "\n",
    "def filter_models_sku_usages(criteria, models_sku_usages):\n",
    "    return list(filter(lambda msu: criteria(**msu), models_sku_usages))\n",
    "\n",
    "editor_req = model_matches(model_names = ['gpt-35-turbo', 'gpt-35-turbo-16k'], tpm = 10, sku_names = ['Standard', 'GlobalStandard'])\n",
    "eval_req = model_matches(model_names = ['gpt-4', 'gpt-4-32k'], tpm = 5, sku_names = ['Standard', 'GlobalStandard'])\n",
    "writer_req = model_matches(model_names = ['gpt-4o', 'gpt-4o-mini'], tpm = 15, sku_names = ['Standard', 'GlobalStandard'])\n",
    "embedding_req = model_matches(model_names = ['text-embedding-3-small', 'text-embedding-ada-002'], tpm = 30, sku_names = ['Standard', 'GlobalStandard'])\n",
    "\n",
    "requirements = [editor_req, eval_req, writer_req, embedding_req]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1ffd7-3c02-415e-b32d-ad859fda452a",
   "metadata": {},
   "source": [
    "## Find all models matching requirements\n",
    "\n",
    "Let's say you want to get an overview of all models matching any of the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00872a7a-6e10-494d-9c07-72bf6685a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = __or__(editor_req, embedding_req)\n",
    "\n",
    "models_sku_usages_filtered = filter_models_sku_usages(req, joined_model_sku_usages)\n",
    "models_sku_usages_filtered[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa618da-7737-42f7-abe3-625d4a6902cb",
   "metadata": {},
   "source": [
    "## Finding regions matching all requirements\n",
    "\n",
    "Sometimes, you're interested in deploying an AI application in a region where all requirements are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b479a-90cd-4e53-a99b-d6dd448dda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_regions(model_sku_usages):\n",
    "    return set([model_sku_usage['region'] for model_sku_usage in model_sku_usages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb185cc4-243f-4e46-8c2a-450757d59ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions_matching_all(requirements, joined_model_sku_usages):\n",
    "    filter_msu_sets = [filter_models_sku_usages(req, joined_model_sku_usages) for req in requirements]\n",
    "    regions_sets = [unique_regions(model_sku_usages) for model_sku_usages in filter_msu_sets]\n",
    "    #return regions_sets\n",
    "    return set.intersection(*regions_sets)\n",
    "\n",
    "regions_matching_all(requirements, joined_model_sku_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab88ec-5456-43dc-86b1-4ab24d9d2c78",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "\n",
    "- [Azure REST API Browser](https://learn.microsoft.com/en-us/rest/api/)\n",
    "- [Azure Locations API MS Learn](https://learn.microsoft.com/en-us/rest/api/resources/subscriptions/list-locations)\n",
    "- [Azure AI Models API MS Learn](https://learn.microsoft.com/en-us/rest/api/aiservices/accountmanagement/models/list)\n",
    "- [Azure AI Usages API MS Learn](https://learn.microsoft.com/en-us/rest/api/aiservices/accountmanagement/usages/list) (Quotas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86dca8-31ea-4bc1-8f88-0f782c01c64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
