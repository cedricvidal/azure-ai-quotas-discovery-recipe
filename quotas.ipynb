{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f82eef",
   "metadata": {},
   "source": [
    "## Get subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e63c0b-dce5-4c8d-a27c-c7ab67739cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from azure.mgmt.subscription import SubscriptionClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "sub_client = SubscriptionClient(credential)\n",
    "subscription = next(sub_client.subscriptions.list(), None)\n",
    "if not subscription:\n",
    "    raise Exception(\"Authenticate using the az cli\")\n",
    "subscriptionId = subscription.subscription_id\n",
    "print(f\"Using subscription {subscriptionId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f06e6",
   "metadata": {},
   "source": [
    "## Getting regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = credential.get_token('https://management.azure.com/.default')\n",
    "headers = {'Authorization': 'Bearer ' + token.token}\n",
    "\n",
    "unique_region_names = set()\n",
    "\n",
    "def get_regions():\n",
    "    locations_request = f\"https://management.azure.com/subscriptions/{subscriptionId}/locations?api-version=2021-04-01\"\n",
    "    response = requests.get(locations_request, headers=headers)\n",
    "    data = json.loads(response.text)\n",
    "    return data[\"value\"]\n",
    "\n",
    "#get_regions()\n",
    "\n",
    "geographyGroups = set()\n",
    "for item in get_regions():\n",
    "    metadata = item['metadata']\n",
    "    geographyGroup = metadata['geographyGroup'] if 'geographyGroup' in metadata else None\n",
    "    if geographyGroup in ['US']:\n",
    "        unique_region_names.add(item[\"name\"])\n",
    "    if geographyGroup:\n",
    "        geographyGroups.add(geographyGroup)\n",
    "\n",
    "regions_list = list(unique_region_names)\n",
    "\n",
    "print(regions_list)\n",
    "print(geographyGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3167d-58a0-4d20-92a2-fb2ad88e8694",
   "metadata": {},
   "source": [
    "## Helper to parallelize calls per region\n",
    "\n",
    "Most of the API calls we'll need to make going forward are per region, the following helper will allow us to run queries in parallel for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942e184-d2b2-4a8a-9794-ba080d9acf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(fn, *iterables, executor=None, **kwargs):\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    \"\"\"\n",
    "    Equivalent to executor.map(fn, *iterables),\n",
    "    but displays a tqdm-based progress bar.\n",
    "    \n",
    "    Does not support timeout or chunksize as executor.submit is used internally\n",
    "    \n",
    "    **kwargs is passed to tqdm.\n",
    "    \"\"\"\n",
    "    with executor if executor else ThreadPoolExecutor(max_workers=len(regions_list)) as ex:\n",
    "        futures = []\n",
    "        for iterable in iterables:\n",
    "            futures += [ex.submit(fn, i) for i in iterable]\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), **kwargs):\n",
    "            yield f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743342ec-c845-4c1f-8d69-c91cbf01b258",
   "metadata": {},
   "source": [
    "## Find regions where Azure AI is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad818e-8657-4077-b4fa-01bfe4854845",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_successful = []\n",
    "regions_failed = []\n",
    "\n",
    "def get_models_response(region):\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/models?api-version=2023-05-01\"\n",
    "    return (region, requests.get(url, headers=headers))\n",
    "\n",
    "for (region, result) in parallel_map(get_models_response, regions_list):\n",
    "    if result.status_code == 200:\n",
    "        regions_successful.append(region)\n",
    "    else:\n",
    "        regions_failed.append(region)\n",
    "\n",
    "print(\"Potential Azure OpenAI regions based on control plane response:\")\n",
    "print(regions_successful)\n",
    "\n",
    "print(\"Azure OpenAI Not Supported:\")\n",
    "print(regions_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4e937-6d43-402f-b7de-34db8bdf4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(region):\n",
    "    (_, response) = get_models_response(region)\n",
    "    parsed = json.loads(response.text)\n",
    "    return parsed['value']\n",
    "\n",
    "#get_models('eastus2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea60ee9-fb84-49db-b432-a8d38aafe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_model_data = {}  \n",
    "\n",
    "excluded_models =  ['text-similarity-ada-001', 'text-babbage-001', 'text-curie-001', 'text-similarity-curie-001', 'text-davinci-002','text-davinci-003', 'text-davinci-fine-tune-002', 'code-davinci-002', 'code-davinci-fine-tune-002','text-ada-001', 'text-search-ada-doc-001', 'text-search-ada-query-001', 'code-search-ada-code-001','code-search-ada-text-001', 'text-similarity-babbage-001', 'text-search-babbage-doc-001','text-search-babbage-query-001', 'code-search-babbage-code-001', 'code-search-babbage-text-001', 'text-search-curie-doc-001', 'text-search-curie-query-001', 'text-davinci-001','text-similarity-davinci-001', 'text-search-davinci-doc-001', 'text-search-davinci-query-001','code-cushman-001']\n",
    "\n",
    "for region in regions_successful:\n",
    "    data_test = []\n",
    "\n",
    "    for item in get_models(region):\n",
    "        model_name = None\n",
    "        version = None\n",
    "        sku_name = None\n",
    "        if item[\"model\"][\"capabilities\"].get(\"scaleType\") == \"Manual\": #skip legacy models\n",
    "            continue\n",
    "        model_name = item[\"model\"][\"name\"]\n",
    "        if model_name in excluded_models: # if in list skip\n",
    "            continue\n",
    "        version = item[\"model\"][\"version\"]\n",
    "        rdate = item[\"model\"][\"deprecation\"]\n",
    "        for sku in item[\"model\"][\"skus\"]:\n",
    "            sku_name = sku[\"name\"]\n",
    "        if sku_name == \"Standard\": # This example is only targeting Standard Model deployments SKUI\n",
    "            data_test.append({\"Model Name\": model_name, \"Version\": version, \"SKU Name\": sku_name})\n",
    "                #print(data_test)\n",
    "\n",
    "    region_model_data[region] = data_test  # store the model data under corresponding region name\n",
    "\n",
    "# Print result\n",
    "for region, model_data in region_model_data.items():\n",
    "    print(f'{region}: {model_data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792227a-a3a2-4310-8d7f-f927e3439f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for region, models in region_model_data.items():\n",
    "    for model in models:\n",
    "        row = model.copy()  \n",
    "        row['Region'] = region  \n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df[['Region', 'Model Name', 'Version', 'SKU Name']]\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df['Exist'] = True \n",
    "pivot_df = df.pivot_table(index='Region', columns=['Model Name', 'Version'], values='Exist', fill_value=False, aggfunc='any')\n",
    "pivot_df.reset_index(inplace = True)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc05d8d-9792-4fc1-ad6a-ac0d4340b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_type(usage_name_localized_value):\n",
    "    if 'Tokens Per Minute' in usage_name_localized_value:\n",
    "        return 'tokens-per-minute'\n",
    "    elif 'Requests Per Minute' in usage_name_localized_value:\n",
    "        return 'requests-per-minute'\n",
    "    elif 'Enqueued tokens' in usage_name_localized_value:\n",
    "        return 'enqueued-tokens'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_model_info(usage):\n",
    "    '''Extracts model vendor, SKU and name from the value using regular expressions.\n",
    "    Value example: OpenAI.Standard.gpt-35-turbo or OpenAI.Standard.gpt-35-turbo-finetune'''\n",
    "    localized = usage['name']['localizedValue'].lower()\n",
    "    if not 'tokens' in localized and not 'requests' in localized: # Skip if not a token usage\n",
    "        return\n",
    "    # Updated pattern to match finetune suffix and classify work type\n",
    "    pattern = r'(?P<vendor>\\w+)\\.(?P<SKU>\\w+)\\.(?P<name>[\\w-]+?)(?:-finetune)?$'\n",
    "    match = re.match(pattern, usage['name']['value'])\n",
    "    if match:\n",
    "        result = match.groupdict()\n",
    "        # Determine work type based on the presence of the 'finetune' suffix\n",
    "        result['workload'] = 'finetune' if usage['name']['value'].endswith('-finetune') else 'inference'\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "def extract_usage_details(region, usage):\n",
    "    '''Extracts region, name, localizedValue, type, currentValue, limit, unit from the item'''\n",
    "    model_info = extract_model_info(usage)\n",
    "    currentValue = usage['currentValue']\n",
    "    limit = usage['limit']\n",
    "    if 'thousands' in usage['name']['localizedValue']:\n",
    "        currentValue *= 1000\n",
    "        limit *= 1000\n",
    "    remaining = limit - currentValue\n",
    "    return {\n",
    "        'region': region,\n",
    "        'value': usage['name']['value'],\n",
    "        'localizedValue': usage['name']['localizedValue'],\n",
    "        'type': infer_type(usage['name']['localizedValue']),\n",
    "        'modelName': model_info['name'] if model_info else None,\n",
    "        'vendor': model_info['vendor'] if model_info else None,\n",
    "        'SKU': model_info['SKU'] if model_info else None,\n",
    "        'workload': model_info['workload'] if model_info else None,\n",
    "        'current': currentValue,\n",
    "        'remaining': remaining,\n",
    "        'limit': limit,\n",
    "        'unit': usage['unit']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85086c3e-f327-4ef3-9b8a-c760cf27f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_model_quota_data = {}\n",
    "\n",
    "# List of models to exclude\n",
    "exclude_models = [\"Code-Cushman-001\", \"code-cushman-fine-tune-002\", \"Code-Search-Ada-Code-001\", \"Code-Search-Ada-Text-001\", \"Text-Ada-001\", \"Text-Search-Ada-Doc-001\", \"Text-Search-Ada-Query-001\", \"Text-Similarity-Ada-001\", \"Babbage\", \"Code-Search-Babbage-Code-001\", \"Code-Search-Babbage-Text-001\", \"Text-Babbage-001\", \"Text-Search-Babbage-Doc-001\", \"Text-Search-Babbage-Query-001\", \"Text-Similarity-Babbage-001\", \"Curie\", \"Text-Curie-001\", \"Text-Search-Curie-Doc-001\", \"Text-Search-Curie-Query-001\", \"Text-Similarity-Curie-001\", \"Code-Davinci-002\", \"Code-Davinci-Fine-Tune-002\", \"Davinci\", \"Text-Davinci-001\", \"Text-Davinci-002\", \"Text-Davinci-003\", \"Text-Davinci-Fine-Tune-002\", \"Text-Search-Davinci-Doc-001\", \"Text-Search-Davinci-Query-001\", \"Text-Similarity-Davinci-001\", \"Code-Cushman-001\", \"code-cushman-fine-tune-002\",  \"Ada\", \"Code-Search-Ada-Code-001\", \"Code-Search-Ada-Text-001\", \"Text-Ada-001\", \"Text-Search-Ada-Doc-001\", \"Text-Search-Ada-Query-001\", \"Text-Similarity-Ada-001\", \"Babbage\", \"Code-Search-Babbage-Code-001\", \"Code-Search-Babbage-Text-001\", \"Text-Babbage-001\", \"Text-Search-Babbage-Doc-001\", \"Text-Search-Babbage-Query-001\", \"Text-Similarity-Babbage-001\", \"Curie\", \"Text-Curie-001\", \"Text-Search-Curie-Doc-001\", \"Text-Search-Curie-Query-001\", \"Text-Similarity-Curie-001\", \"Code-Davinci-Fine-Tune-002\", \"Davinci\", \"Text-Davinci-001\", \"Text-Davinci-002\", \"Text-Davinci-003\", \"Text-Davinci-Fine-Tune-002\", \"Text-Search-Davinci-Doc-001\", \"Text-Search-Davinci-Query-001\", \"Text-Similarity-Davinci-001\"]\n",
    "\n",
    "def get_usages(region):\n",
    "    url = f\"https://management.azure.com/subscriptions/{subscriptionId}/providers/Microsoft.CognitiveServices/locations/{region}/usages?api-version=2023-05-01\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return json.loads(response.text)['value']\n",
    "\n",
    "region='eastus2'\n",
    "usages = get_usages(region)\n",
    "usages\n",
    "token_limit_details = [extract_usage_details(region, usage) for usage in usages]\n",
    "token_limit_details\n",
    "\n",
    "## Convert the list to a DataFrame\n",
    "df = pd.DataFrame(token_limit_details)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df[df['modelName'].notnull()]\n",
    "#df[df['modelName'] == 'gpt-4o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf62e6-a8e3-40d8-ae9b-d378b3b867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "usages[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739867c-19fe-4e9f-a4ea-aa626712c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def usage_name_reducer(j, u):\n",
    "    j[u['name']['value']] = u\n",
    "    return j\n",
    "usages_by_name = reduce(usage_name_reducer, usages, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70933e53-b727-47df-878b-695c54157920",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models('eastus2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88626eda-64b3-46ff-a027-03782fd95a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_models_sku(models):\n",
    "    for model in models:\n",
    "        skus = model['model']['skus'] or [None]\n",
    "        for sku in skus:\n",
    "            yield (model, sku)\n",
    "models_flattened = list(flatten_models_sku(models))\n",
    "models_flattened[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b55e75-edf5-475b-8242-b04db95c18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_models_usages(models_flattened, usages_by_name):\n",
    "    for (model, sku) in models_flattened:\n",
    "        usage = None\n",
    "        if sku:\n",
    "            usageName = sku['usageName']\n",
    "            usage = usages_by_name[usageName]\n",
    "        yield (model, sku, usage)\n",
    "\n",
    "joined_model_sku_usages = list(join_models_usages(models_flattened, usages_by_name))\n",
    "joined_model_sku_usages[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060ccd6-6f8a-480d-b034-26d81a313b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria(model, sku, usage):\n",
    "    if not usage:\n",
    "        return False\n",
    "    limit = usage['limit']\n",
    "    current = usage['currentValue']\n",
    "    remaining = limit - current\n",
    "    modelName = model['model']['name']\n",
    "    skuName = sku['name']\n",
    "    return modelName == 'gpt-35-turbo' and remaining > 10 and skuName in ['Standard', 'GlobalStandard']\n",
    "\n",
    "list(filter(lambda msu: criteria(msu[0], msu[1], msu[2]), joined_model_sku_usages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54900598-0a60-40de-a751-66d27b5786c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
